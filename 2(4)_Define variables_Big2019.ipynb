{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Running the Packages and parameters script which imports all the necessary packages and speifies parmeters for plotting\n",
    "# Also specifying the order of the treatments when plotting so they all get the same color in every graph\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import spatial\n",
    "from scipy import ndimage\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage import feature\n",
    "from skimage import morphology\n",
    "import pickle\n",
    "from scipy import stats\n",
    "from scipy import signal\n",
    "import time\n",
    "import importlib\n",
    "import h5py\n",
    "import fl\n",
    "import warnings\n",
    "import sys\n",
    "#from termcolor import colored\n",
    "from multiprocessing import Pool\n",
    "from nd2reader import ND2Reader\n",
    "#from scipy.misc import imread\n",
    "import statsmodels.api as sm\n",
    "from pathlib import Path\n",
    "from scipy.stats import sem\n",
    "\n",
    "#Parameters for export to Illustrator\n",
    "#---------------------------------------------------------------------------\n",
    "#matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "#matplotlib.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "#plt.rcParams['interpolation'] = 'none'\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Plot parameters & Styles\n",
    "#---------------------------------------------------------------------------\n",
    "#sns.set_style('darkgrid')\n",
    "#sns.set_style('whitegrid')\n",
    "sns.set_style('ticks')\n",
    "#sns.set_context(\"talk\") #paper,notebook,talk,poster\n",
    "sns.set_context(\"poster\")\n",
    "plt.rcParams['image.cmap'] = 'jet'\n",
    "pal_bw='Greys'\n",
    "pal_few_c='Set1'\n",
    "pal_many_c='muted'\n",
    "plot_height=6\n",
    "plot_aspect=1.25\n",
    "ci_1=70\n",
    "time_lim=[0,600]\n",
    "time_ticks=[0,250,500]\n",
    "title_pos=0.9\n",
    "title_size=25\n",
    "#---------------------------------------------------------------------------\n",
    "# Orders of variables for plotting \n",
    "\n",
    "\n",
    "#Create lists that specify the order of the variable values in the graphs\n",
    "mov_class_order=['still','contractile','loose','none']\n",
    "mov_class_order1=['still','contractile','loose']\n",
    "movement_order=['immobile','contracting','drifting','unstable','none']\n",
    "movement_order1=['immobile','contracting','drifting','unstable']\n",
    "movements_order2=['immobile','contracting','drifting']\n",
    "position_order=['head','tail','outside']\n",
    "\n",
    "#inh_order1=['ctrl','biva','par4--','cang','par4--biva']\n",
    "inh_order=['ctrl','saline','biva','par4--','cang','par4--biva']\n",
    "inh_order1=['saline','biva','par4--','cang','par4--biva']\n",
    "inh_order_thrombin=['saline','biva','par4--','par4--biva']\n",
    "inh_labels=['Control','Saline','Bivalirudin','PAR4-/-','Cangrelor','PAR4-/- + Bivalirudin']\n",
    "inh_labels1=['Saline','Bivalirudin','PAR4 -/-','Cangrelor','PAR4 -/- + Bivalirudin']\n",
    "bol_order=[True,False]\n",
    "#pal = dict(zip(days, sns.color_palette(\"Set1\", n_colors=len(days))))\n",
    "\n",
    "\n",
    "\n",
    "importlib.reload(fl)\n",
    "%matplotlib inline\n",
    "warnings.simplefilter(action = \"ignore\", category = FutureWarning)\n",
    "processors=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['image.cmap'] = 'jet'\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/Users/jni/projects/pia-tracking/')# PIA Manually change the path to the folder including the outputdata\n",
    "#For some reason the path name requires double backslashes here.\n",
    "\n",
    "dirs = [e for e in path.iterdir() if e.is_dir()]\n",
    "for c,e in enumerate (dirs):\n",
    "    print(c,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIA specify which of the dirs listed above that the script should use (the one containing the pickle files from script 1)\n",
    "\n",
    "data_path = dirs[2]\n",
    "\n",
    "# C:\\Users\\piamaril\\Python\\Scripts\\200823_Test\\20200823-112806\n",
    "# C:\\Users\\piamaril\\Python\\Scripts\\200612\\20200613-214101\n",
    "#'D:/Forskning/Tracking/Intravital/Demo Injury for Python/200116'\n",
    "#'C:/Users/Human/Google Drive/IVM sharing/IVM Tracking/Data/Demo experiments 200114'\n",
    "#'D:/Forskning/Tracking/Intravital/Demo Injury for Python'\n",
    "#C:/Users/Lars2/Desktop/IVM sharing/IVM Tracking/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=fl.get_objectDF_files(dirs[2]) # PIA change to correct dirs[x] here too\n",
    "#'C:\\\\Users\\\\Human\\\\Google Drive\\\\IVM sharing\\\\IVM Tracking\\\\Scripts\\\\New fl 200116')#dirs[3])\n",
    "print(f\"There are {len(files)} pointcloud files in the data_path \\nList of files in data_path:\")\n",
    "for c, value in enumerate(files,0):\n",
    "    print(c, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIA change the range depending on how many injuries in data set. If a test injury use flist=[0] \n",
    "#If a list of injuries of example 66 injuries: write (1,65,1) - IS THIS CORRECT??? (0,65,1)???\n",
    "#Put hashtag on the one that you are not using\n",
    "flist=[0]\n",
    "#flist=list(range(1,65,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df=[]\n",
    "for n in flist:\n",
    "    pc_=pd.read_pickle(files[n])\n",
    "    print(f\"Observations in file number {n} = {pc_.shape[0]}\")\n",
    "    ls_df.append(pc_)\n",
    "pc=pd.concat(ls_df)\n",
    "print(f\"Total number of observations = {pc.shape[0]}\")\n",
    "print(f\"Average number of observations per exp = {int(pc.shape[0]/len(flist))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pc.head(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Columns ', pc.columns, '\\nDimensions ',pc.shape, '\\nFrames ', len(pd.unique(pc.frame)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load PC collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.unique(pc.path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ytterligare Filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(np.geomspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OM DET BEHÖVS, renso objekt från mindre objekt (skräp), och se hur många objekt före och efter\n",
    "\n",
    "\n",
    "print(f\"{pc.shape[0]} \\t\\t objects\\n\")\n",
    "for n in list(np.around(np.geomspace(4, 1024, num=9)).astype(int)):\n",
    "        if n<129:\n",
    "            print(f\"{len(pc[pc['size']<n])} \\t\\t smaller than \\t\\t {n} \\t\\t pixels\")\n",
    "        else:\n",
    "            print(f\"{len(pc[pc['size']>n])} \\t\\t larger than \\t\\t {n} \\t\\t pixels\")\n",
    "#print(f\"{len(pc[pc['size']>1024])} \\t\\t larger than \\t\\t 1024 \\t\\t pixels\")\n",
    "    #print(f\"There are {k}\")\n",
    "    #print('hello')  \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reset index, drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc['pid']=list(range(pc.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pc.head(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.tail(3).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.set_index('pid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc[['size','c0_max','c1_max']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.tail(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trackpy as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for tracking. Seach range = 3 um with these settings - change?\n",
    "def track(pct):\n",
    "    search_range = 3 #4\n",
    "    #pred = tp.predict.NearestVelocityPredict()#Predikterar position utifran tidigare hastighet\n",
    "    #linked_pc = pred.link_df(pct, search_range, pos_columns=['xs', 'ys', 'zs'], memory=1)\n",
    "    linked_pc = tp.link_df(pct, search_range, pos_columns=['xs', 'ys', 'zs'], memory=1)\n",
    "    #pred = trackpy.predict.NearestVelocityPredict()\n",
    "    #tr = pred.link_df(pandas.concat(frames), 0.5)\n",
    "    return(linked_pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying tracking function to find trajectories ?\n",
    "t_grp=pc.reset_index().groupby(['path']).apply(track)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_grp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy = t_grp.drop(['path'], axis=1).reset_index().drop(['level_1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy.to_csv('/Users/jni/Dropbox/share-files/tracks.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tracks=t_grp.drop(['path'], axis=1).reset_index().sort_values('pid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_=[]\n",
    "\n",
    "p_grp=tracks.groupby(['path', 'particle'])\n",
    "for i, gr in p_grp:\n",
    "    grp=gr.sort_values('frame')\n",
    "    dvx = np.append(np.diff(grp['xs']), np.nan)\n",
    "    dvy = np.append(np.diff(grp['ys']), np.nan)\n",
    "    dvz = np.append(np.diff(grp['zs']), np.nan)\n",
    "    df=grp.pid.to_frame()\n",
    "    df['dvx']=dvx\n",
    "    df['dvy']=dvy\n",
    "    df['dvz']=dvz\n",
    "    df['particle']=grp.particle\n",
    "    \n",
    "    dv_.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv=pd.concat(dv_, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv=dv.sort_values('pid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv['dv']=(dv.dvx**2+dv.dvy**2+dv.dvz**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_grp=dv.sort_values('pid').reset_index()\n",
    "tracks_grp=tracks_grp[['pid', 'dvx', 'dvy', 'dvz', 'dv', 'particle']].set_index('pid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_grp.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb(pc):\n",
    "    nb_count=3\n",
    "    key_dist={}\n",
    "    key_idx={}\n",
    "    #print(len(pc))\n",
    "    p1i=pc.reset_index().pid\n",
    "    if len(pc)>nb_count:\n",
    "        \n",
    "        dmap=spatial.distance.squareform(spatial.distance.pdist(pc[['xs','ys','zs']].values))\n",
    "        dmap_sorted=np.sort(dmap, axis=0)\n",
    "        dmap_idx_sorted=np.argsort(dmap, axis=0)\n",
    "        for i in range(nb_count):\n",
    "\n",
    "            nb_dist=(dmap_sorted[i+1,:])\n",
    "            nb_idx=dmap_idx_sorted[i+1,:]\n",
    "            key_dist['nb_d_' + str(i)]=nb_dist\n",
    "            key_idx['nb_i_' + str(i)]=pd.Series(nb_idx).map(p1i).values.astype('int').tolist()\n",
    "        key_idx.update(key_dist)\n",
    "    else:\n",
    "        a = np.empty((len(pc)))\n",
    "        a[:] = np.nan\n",
    "        key_idx['nb_i_0']=a\n",
    "    \n",
    "    df=pd.DataFrame(key_idx)\n",
    "    df=pd.concat([p1i, df], axis=1)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_grp=pc.set_index('pid').groupby(['path', 'frame']).apply(nb).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_grp=t_grp.set_index('pid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_grp.head(3)#.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_grp=t_grp.drop(['path', 'frame', 'level_2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_grp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbours - Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb(pc):\n",
    "    nb_count=3\n",
    "    nba_list=[5,10,15]\n",
    "    key_dist={}\n",
    "    key_idx={}\n",
    "    #print(len(pc))\n",
    "    p1i=pc.reset_index().pid\n",
    "    if len(pc)>np.array(nba_list).max():\n",
    "        \n",
    "        dmap=spatial.distance.squareform(spatial.distance.pdist(pc[['xs','ys','zs']].values))\n",
    "        dmap_sorted=np.sort(dmap, axis=0)\n",
    "        #dmap_idx_sorted=np.argsort(dmap, axis=0)\n",
    "        for i in nba_list:\n",
    "\n",
    "            nb_dist=(dmap_sorted[1:(i+1),:]).mean(axis=0)\n",
    "            #nb_idx=dmap_idx_sorted[i+1,:]\n",
    "            key_dist['nba_d_' + str(i)]=nb_dist\n",
    "            #key_idx['nb_i_' + str(i)]=pd.Series(nb_idx).map(p1i).values.astype('int').tolist()\n",
    "        #key_idx.update(key_dist)\n",
    "    else:\n",
    "        a = np.empty((len(pc)))\n",
    "        a[:] = np.nan\n",
    "        key_dist[('nba_d_' + str(nba_list[0]))]=a\n",
    "    \n",
    "    df=pd.DataFrame(key_dist)\n",
    "    df=pd.concat([p1i, df], axis=1)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_grp=pc.set_index('pid').groupby(['path', 'frame']).apply(nb).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_grp=t_grp.set_index('pid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_grp=t_grp.drop(['path', 'frame', 'level_2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_grp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbours -  all colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def nbc(pc):\n",
    "    nb_count=3\n",
    "    key_dist={}\n",
    "    key_idx={}\n",
    "    #print(len(pc))\n",
    "    p1i=pc.reset_index().pid\n",
    "    if len(pc)>nb_count:\n",
    "        \n",
    "        dmap=spatial.distance.squareform(spatial.distance.pdist(pc[['xs','ys','zs']].values))\n",
    "        dmap_sorted=np.sort(dmap, axis=0)\n",
    "        dmap_idx_sorted=np.argsort(dmap, axis=0)\n",
    "        for i in range(nb_count):\n",
    "\n",
    "            nb_dist=(dmap_sorted[i+1,:])\n",
    "            nb_idx=dmap_idx_sorted[i+1,:]\n",
    "            key_dist['nbc_d_' + str(i)]=nb_dist\n",
    "            key_idx['nbc_i_' + str(i)]=pd.Series(nb_idx).map(p1i).values.astype('int').tolist()\n",
    "        key_idx.update(key_dist)\n",
    "    else:\n",
    "        a = np.empty((len(pc)))\n",
    "        a[:] = np.nan\n",
    "        key_idx['nbc_i_0']=a\n",
    "        \n",
    "    \n",
    "    df=pd.DataFrame(key_idx)\n",
    "    df=pd.concat([p1i, df], axis=1)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t_grp=pc.set_index('pid').groupby(['path', 'frame']).apply(nbc).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "t_grp=t_grp.set_index('pid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nbc_grp=t_grp.drop(['path', 'frame', 'level_2'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nbc_grp.sort_index().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbours -  all colors - Average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def nbca(pc):\n",
    "    nb_count=3\n",
    "    nba_list=[5,10,15]\n",
    "    key_dist={}\n",
    "    key_idx={}\n",
    "    #print(len(pc))\n",
    "    p1i=pc.reset_index().pid\n",
    "    if len(pc)>np.array(nba_list).max():\n",
    "        \n",
    "        dmap=spatial.distance.squareform(spatial.distance.pdist(pc[['xs','ys','zs']].values))\n",
    "        dmap_sorted=np.sort(dmap, axis=0)\n",
    "        #dmap_idx_sorted=np.argsort(dmap, axis=0)\n",
    "        for i in nba_list:\n",
    "\n",
    "            nb_dist=(dmap_sorted[1:(i+1),:]).mean(axis=0)\n",
    "            #nb_idx=dmap_idx_sorted[i+1,:]\n",
    "            key_dist['nbca_d_' + str(i)]=nb_dist\n",
    "            #key_idx['nb_i_' + str(i)]=pd.Series(nb_idx).map(p1i).values.astype('int').tolist()\n",
    "        #key_idx.update(key_dist)\n",
    "    else:\n",
    "        a = np.empty((len(pc)))\n",
    "        a[:] = np.nan\n",
    "        key_dist[('nbca_d_' + str(nba_list[0]))]=a\n",
    "    \n",
    "    df=pd.DataFrame(key_dist)\n",
    "    df=pd.concat([p1i, df], axis=1)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t_grp=pc.set_index('pid').groupby(['path', 'frame']).apply(nbca).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t_grp=t_grp.set_index('pid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nbca_grp=t_grp.drop(['path', 'frame', 'level_2'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nbca_grp.sort_index().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbours -  second color only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p=0\n",
    "pc1=pc[pc.path==(pd.unique(pc.path)[p])]\n",
    "#pc1=df[df.c==625]\n",
    "pc1=pc1[pc1.frame==20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.unique(pc.c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def nbc2(pc1):\n",
    "    c1=470\n",
    "    c2=555\n",
    "\n",
    "    nb_count=3\n",
    "    key_dist={}\n",
    "    key_idx={}\n",
    "\n",
    "\n",
    "    #print(len(pc))\n",
    "    if (len(pc1[pc1.c==c1])>nb_count) & (len(pc1[pc1.c==c2])>nb_count):\n",
    "        pos1=pc1[pc1.c==c1]\n",
    "        #print(len(pos1))\n",
    "        p1i=pos1.reset_index().pid\n",
    "        pos1=pos1[['xs','ys','zs']].values\n",
    "        pos2=pc1[pc1.c==c2]\n",
    "        #print(len(pos2))\n",
    "        p2i=pos2.reset_index().pid\n",
    "        pos2=pos2[['xs','ys','zs']].values\n",
    "\n",
    "        dmap=spatial.distance.cdist(pos1, pos2)\n",
    "\n",
    "        key_dist={}\n",
    "        key_idx={}\n",
    "        dmap_sorted=np.sort(dmap.T, axis=0)\n",
    "        dmap_idx_sorted=np.argsort(dmap.T, axis=0)\n",
    "        for i in range(nb_count):\n",
    "            nb_dist=(dmap_sorted[i+1,:])\n",
    "            nb_idx=dmap_idx_sorted[i+1,:]\n",
    "            key_dist['nbc2_d_' + str(i)]=nb_dist\n",
    "            key_idx['nbc2_i_' + str(i)]=pd.Series(nb_idx).map(p1i).values.astype('int').tolist()\n",
    "        key_idx.update(key_dist)\n",
    "        p1=pd.DataFrame(key_idx)\n",
    "        p1=pd.concat([p1,p1i], axis=1).set_index('pid')\n",
    "\n",
    "        key_dist={}\n",
    "        key_idx={}\n",
    "        dmap_sorted=np.sort(dmap, axis=0)\n",
    "        dmap_idx_sorted=np.argsort(dmap, axis=0)\n",
    "        for i in range(nb_count):\n",
    "            nb_dist=(dmap_sorted[i+1,:])\n",
    "            nb_idx=dmap_idx_sorted[i+1,:]\n",
    "            key_dist['nbc2_d_' + str(i)]=nb_dist\n",
    "            key_idx['nbc2_i_' + str(i)]=pd.Series(nb_idx).map(p2i).values.astype('int').tolist()\n",
    "        key_idx.update(key_dist)\n",
    "        p2=pd.DataFrame(key_idx)\n",
    "        p2=pd.concat([p2,p2i], axis=1).set_index('pid')\n",
    "        \n",
    "        df=pd.concat([p1,p2], axis=0).sort_index()\n",
    "\n",
    "    else:\n",
    "        a = np.empty((len(pc1)))\n",
    "        a[:] = np.nan\n",
    "        key_idx['nbc2_i_0']=a\n",
    "        pi=pc1.reset_index().pid\n",
    "        df=pd.DataFrame(key_idx)\n",
    "        df=pd.concat([df,pi], axis=1).set_index('pid')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t_grp=pc.set_index('pid').groupby(['path', 'frame']).apply(nbc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "t_grp=t_grp.reset_index().set_index('pid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nbc2_grp=t_grp.drop(['path', 'frame'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nbc2_grp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN - is this a measure of object clustering? We have not used this so far but we might find interesting inforamation here especially in the arms. Optimise this code furhter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "#from sklearn.datasets.samples_generator import make_blobs\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def cluster(pc):\n",
    "    \n",
    "    \n",
    "    min_samples=5\n",
    "    \n",
    "    eps_list=[5,7.5,10,15,20]\n",
    "    \n",
    "    cl_=[]\n",
    "    \n",
    "    #X=pos[:,:-1] # 2D\n",
    "    X=pc[['xs','ys','zs']].values # 3D\n",
    "    \n",
    "    for eps in eps_list:\n",
    "        # Compute DBSCAN\n",
    "        db = DBSCAN(eps=eps, min_samples=min_samples).fit(X)\n",
    "        core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "        core_samples_mask[db.core_sample_indices_] = True\n",
    "        labels = db.labels_\n",
    "\n",
    "        # Number of clusters in labels, ignoring noise if present.\n",
    "        n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "        #print('Estimated number of clusters: %d' % n_clusters_)\n",
    "        \n",
    "        cl_.append(pd.DataFrame({('cl_idx_' + str(eps) ) : (labels)}))\n",
    "                     \n",
    "    \n",
    "\n",
    "        \n",
    "    ##############################################################################\n",
    "    # Plot result\n",
    "\n",
    "    # Black removed and is used for noise instead.\n",
    "    \n",
    "#    unique_labels = set(labels)\n",
    "#    colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
    "#    for k, col in zip(unique_labels, colors):\n",
    "#        if k == -1:\n",
    "#            # Black used for noise.\n",
    "#            col = 'k'\n",
    "\n",
    "#        class_member_mask = (labels == k)\n",
    "\n",
    "#        xy = X[class_member_mask & core_samples_mask]\n",
    "#       plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,\n",
    "#                 markeredgecolor='k', markersize=8)\n",
    "\n",
    "#        xy = X[class_member_mask & ~core_samples_mask]\n",
    "#        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,\n",
    "#                 markeredgecolor='k', markersize=3)\n",
    "\n",
    "#    plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "#    plt.show()\n",
    "    cl_.append(pc.reset_index().pid)\n",
    "    return (pd.concat(cl_, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_grp=pc.groupby(['path', 'frame']).apply(cluster).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_grp=t_grp.drop(['path', 'frame', 'level_2'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_grp=cl_grp.set_index('pid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_grp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "#from sklearn.datasets.samples_generator import make_blobs\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def cluster_d(pc):\n",
    "    \n",
    "    min_samples=5\n",
    "    \n",
    "    eps_list=np.arange(3, 31, 2)\n",
    "    \n",
    "    cl_=[]\n",
    "    \n",
    "    #X=pos[:,:-1] # 2D\n",
    "    X=pc[['xs','ys','zs']].values # 3D\n",
    "    \n",
    "    for eps in eps_list:\n",
    "        # Compute DBSCAN\n",
    "        db = DBSCAN(eps=eps, min_samples=min_samples).fit(X)\n",
    "        core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "        core_samples_mask[db.core_sample_indices_] = True\n",
    "        labels = db.labels_\n",
    "\n",
    "        # Number of clusters in labels, ignoring noise if present.\n",
    "        n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "        #print('Estimated number of clusters: %d' % n_clusters_)\n",
    "        \n",
    "        labels[labels>-1]=eps\n",
    "        labels[labels==-1]=42\n",
    "        \n",
    "               \n",
    "        cl_.append(pd.DataFrame({('cl_idx_' + str(eps) ) : (labels)}))\n",
    "    cld_grp=pd.concat(cl_, axis=1)\n",
    "    cld_grp=pd.DataFrame({('cld' ) : (cld_grp.min(axis=1))})\n",
    "    \n",
    "                     \n",
    "        \n",
    "\n",
    "        \n",
    "    ##############################################################################\n",
    "    # Plot result\n",
    "\n",
    "    # Black removed and is used for noise instead.\n",
    "    \n",
    "#    unique_labels = set(labels)\n",
    "#    colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
    "#    for k, col in zip(unique_labels, colors):\n",
    "#        if k == -1:\n",
    "#            # Black used for noise.\n",
    "#            col = 'k'\n",
    "\n",
    "#        class_member_mask = (labels == k)\n",
    "\n",
    "#        xy = X[class_member_mask & core_samples_mask]\n",
    "#       plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,\n",
    "#                 markeredgecolor='k', markersize=8)\n",
    "\n",
    "#        xy = X[class_member_mask & ~core_samples_mask]\n",
    "#        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,\n",
    "#                 markeredgecolor='k', markersize=3)\n",
    "\n",
    "#    plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "#    plt.show()\n",
    "    cld_grp['pid']=(pc.reset_index().pid)\n",
    "    return (cld_grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_grp=pc.groupby(['path', 'frame']).apply(cluster_d).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_grp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cld_grp=t_grp.drop(['path', 'frame', 'level_2'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cld_grp=cld_grp.set_index('pid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cld_grp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability 2, pc only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_tstab(tgrp):\n",
    "    ocp_=[]\n",
    "    first=True\n",
    "    #print(len(tgrp))\n",
    "    for i, grp in tgrp.groupby(['frame']):\n",
    "        pos=grp[['xs','ys','zs']].values\n",
    "        if first:\n",
    "            first=False\n",
    "        else:\n",
    "            dmap=spatial.distance.cdist(t1, pos)\n",
    "            dmap_sorted=np.sort(dmap, axis=1)\n",
    "            data=dmap_sorted[:,0]\n",
    "\n",
    "            ocp_.append(pd.DataFrame({'stab' : data}))#, 'pid': grp.pid}))\n",
    "\n",
    "        t1=pos\n",
    "    data=np.zeros(len(pos))\n",
    "    data[:]=np.nan\n",
    "    ocp_.append(pd.DataFrame({'stab' : data}))#, 'pid':grp.pid}))\n",
    "\n",
    "    ocp=pd.concat(ocp_, axis=0).reset_index()\n",
    "    ocp['pid']=tgrp.reset_index().pid\n",
    "    \n",
    "    return ocp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_grp=pc.groupby(['path']).apply(do_tstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stab_grp=t_grp.reset_index()[['stab', 'pid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stab_grp=stab_grp.set_index('pid').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stab_grp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def depth(pos):\n",
    "    \n",
    "    fill_dist=15\n",
    "    \n",
    "    pos_max=pos[['xs', 'ys', 'zf']].max()\n",
    "\n",
    "    zsize=int(pos_max['zf']*1.5)\n",
    "    xsize=int(pos_max['xs']*1.1)\n",
    "    ysize=int(pos_max['ys']*1.1)\n",
    "\n",
    "    pcc=np.zeros((xsize+2,ysize+2,zsize+2))\n",
    "    pc_pos=pos[['xs', 'ys', 'zf']].values\n",
    "\n",
    "    #zfloor=int(np.percentile(pc_pos[:,2],2))\n",
    "    zfloor=1\n",
    "    pc_pos[pc_pos<0]=0\n",
    "    pc_pos=pc_pos.astype('int').T\n",
    "    \n",
    "    pc_pos=pc_pos.tolist()\n",
    "      \n",
    "    pcc[pc_pos]=1\n",
    "    pcc[:,:,:zfloor]=1\n",
    "\n",
    "    pcd=ndimage.morphology.distance_transform_edt(pcc==0)\n",
    "\n",
    "    #plt.figure(figsize=(10,3))\n",
    "    #plt.imshow((pcd[300,:,:]).T, cmap='jet', vmin=0, vmax=20)\n",
    "    #plt.colorbar()\n",
    "\n",
    "    pca=pcd<fill_dist\n",
    "\n",
    "    pca=ndimage.binary_fill_holes(pca)\n",
    "\n",
    "    #plt.figure(figsize=(10,3))\n",
    "    #plt.imshow((pca[300,:,:]).T, cmap='jet', vmin=0, vmax=2)\n",
    "    #plt.colorbar()\n",
    "\n",
    "    pcad=ndimage.morphology.distance_transform_edt(pca)\n",
    "\n",
    "    #plt.figure(figsize=(10,3))\n",
    "    #plt.imshow((pcad[300,:,:]).T, cmap='jet', vmin=0, vmax=40)\n",
    "    #plt.colorbar()\n",
    "\n",
    "    pdepth=pcad[pc_pos]-fill_dist\n",
    "           \n",
    "    depth_grp=pd.DataFrame({'depth' : (pdepth)})\n",
    "    \n",
    "    depth_grp['pid']=pos.reset_index().pid\n",
    "    \n",
    "    return depth_grp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def depth(pos_grp):\n",
    "    \n",
    "    fill_dist=15\n",
    "    \n",
    "    pos_max=pos_grp[['xs', 'ys', 'zf']].max()\n",
    "\n",
    "    zsize=int(pos_max['zf']*1.5)\n",
    "    xsize=int(pos_max['xs']*1.1)\n",
    "    ysize=int(pos_max['ys']*1.1)\n",
    "\n",
    "    depth_grp_=[]\n",
    "    \n",
    "    for i, pos in pos_grp.groupby('frame'):\n",
    "    \n",
    "        pcc=np.zeros((xsize+2,ysize+2,zsize+2))\n",
    "        \n",
    "        pc_pos=pos[['xs', 'ys', 'zf']].values\n",
    "        \n",
    "        zfloor=1\n",
    "        pc_pos[pc_pos<0]=0\n",
    "        pc_pos=pc_pos.astype('int').T\n",
    "\n",
    "        pc_pos=pc_pos.tolist()\n",
    "\n",
    "        pcc[pc_pos]=1\n",
    "        pcc[:,:,:zfloor]=1\n",
    "\n",
    "        pcd=ndimage.morphology.distance_transform_edt(pcc==0)\n",
    "        pca=pcd<fill_dist\n",
    "\n",
    "        pca=ndimage.binary_fill_holes(pca)\n",
    "        pcad=ndimage.morphology.distance_transform_edt(pca)\n",
    "        pdepth=pcad[pc_pos]-fill_dist\n",
    "\n",
    "        depth_grp=pd.DataFrame({'depth' : (pdepth)})\n",
    "\n",
    "        depth_grp['pid']=pos.reset_index().pid\n",
    "        \n",
    "        depth_grp_.append(depth_grp)\n",
    "    \n",
    "    depth_grp_=pd.concat(depth_grp_, axis=0)\n",
    "    return depth_grp_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t_grp=pc.groupby(['path']).apply(depth).reset_index()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "depth_grp=t_grp[['pid', 'depth']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "depth_grp=depth_grp.set_index('pid').sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "depth_grp.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pia - change base name to current folder. \n",
    "# Pia Make sure there is no subfolder called mods if the folder was copied from other experiment??? We are making a mods subfolder\n",
    "base_name = '200823_Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder='./mods/'\n",
    "#/tmp/year\n",
    "os.mkdir(folder)\n",
    "base_name=folder + base_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Saving modified point-cloud data as pickle file: file name pc_mod\n",
    "#pc=pc.set_index('pid')\n",
    "pc.to_pickle(base_name + '_pc_mod')\n",
    "print(len(pc))\n",
    "pc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving stabiliy data as pickle file:  file name _stab\n",
    "stab_grp.to_pickle(base_name + '_stab')\n",
    "print(len(stab_grp))\n",
    "stab_grp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_grp.sort_index().to_pickle(base_name + '_cl')\n",
    "print(len(cl_grp))\n",
    "cl_grp.sort_index().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cld_grp.sort_index().to_pickle(base_name + '_cld')\n",
    "print(len(cld_grp))\n",
    "cld_grp.sort_index().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving tracks as pickle file: file name_tracks\n",
    "#tracks_grp=tracks_grp.set_index('pid')\n",
    "tracks_grp.to_pickle(base_name + '_tracks')\n",
    "print(len(tracks_grp))\n",
    "tracks_grp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "depth_grp.to_pickle(base_name + '_depth')\n",
    "print(len(depth_grp))\n",
    "depth_grp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving nearest neighbours data as pickle: file name_nb\n",
    "nb_grp.to_pickle(base_name + '_nb')\n",
    "print(len(nb_grp))\n",
    "nb_grp.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nbc_grp.to_pickle(base_name + '_nbc')\n",
    "print(len(nbc_grp))\n",
    "nbc_grp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving nearest neighbours average data as pickle: file name_nba\n",
    "nba_grp.to_pickle(base_name + '_nba')\n",
    "print(len(nba_grp))\n",
    "nba_grp.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nbca_grp.to_pickle(base_name + '_nbca')\n",
    "print(len(nbca_grp))\n",
    "nbca_grp.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nbc2_grp.to_pickle(base_name + '_nbc2')\n",
    "print(len(nbc2_grp))\n",
    "nbc2_grp.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addon tracking - contraction component (förstör pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pc=pc.reset_index()\n",
    "pc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1=pd.concat([pc[['path', 'xs', 'ys', 'zf', 'pid','frame']].set_index('pid'), tracks_grp], axis=1).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contract(t2):\n",
    "    #xmed, ymed =(t2[t2.frame<50]['xs'].median(), t2[t2.frame<50]['ys'].median())\n",
    "    #xmed, ymed =(t2['xs'].median(), t2['ys'].median())\n",
    "\n",
    "    #t2['xm']=t2['xs']-xmed\n",
    "    #t2['ym']=t2['ys']-ymed\n",
    "\n",
    "    #t2['cont']=((-t2['xm'])*t2['dvx'] + (-t2['ym'])*t2['dvy'] + (-t2['zf'])*t2['dvz'] )/((t2['xm'])**2 + (t2['ym'])**2 + (t2['zf'])**2)**0.5\n",
    "    t2['cont']=((-t2['xs'])*t2['dvx'] + (-t2['ys'])*t2['dvy'] + (-t2['zf'])*t2['dvz'] )/((t2['xs'])**2 + (t2['ys'])**2 + (t2['zf'])**2)**0.5\n",
    "    t2['cont_p']=t2.cont/t2.dv\n",
    "    \n",
    "    \n",
    "    \n",
    "    return pd.DataFrame({'cont' : (t2['cont']), 'cont_p' : (t2['cont_p']), 'pid':t2['pid']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_grp=pc1.reset_index().groupby(['path']).apply(contract)\n",
    "cont_grp=cont_grp.set_index('pid').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_grp.to_pickle(base_name + '_cont')\n",
    "print(len(cont_grp))\n",
    "cont_grp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nytt paket med lite nya numeriska variabler som beskriver tracking och totala rorelser "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These functions give us the extra readouts incluidng tracknr, nrtracks, cont_tot, disp_tot, dvz_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skapar dataframe med grundpaket plus tracking plus kontraktions\n",
    "pc1=pd.concat([pc[['path', 'xs', 'ys', 'zf', 'pid','frame']].set_index('pid'), tracks_grp,cont_grp], axis=1).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Satter index pa path och particle for att kunna konkaternera dataframe senare\n",
    "pc1=pc1.reset_index().set_index(['path','particle'])\n",
    "\n",
    "#Grupperar data pa path och partikel for att kunna analysera olika partiklar for sig\n",
    "grouped=pc1.groupby(['path','particle'])\n",
    "#Raknar antalet observationer for varje unik partikel\n",
    "counted=grouped.count()\n",
    "#Variabeln nrtracks kollar hur manga tracks en viss partikel ar trackad\n",
    "pc1['nrtracks']=counted.frame\n",
    "\n",
    "#Adderar de olika variablerna och beraknar summan av alla observationer\n",
    "summed=grouped.sum()\n",
    "#cont_tot summerar den totala kontraktionen for en partikel\n",
    "pc1['cont_tot']=summed.cont\n",
    "# displ_tot summerar den totala forflyttningen for en partikel\n",
    "pc1['displ_tot']=abs(summed.dvx)+abs(summed.dvy)\n",
    "# dvz_tot summerar den totala forflyttningen i z-led for en partikel\n",
    "pc1['dvz_tot']=summed.dvz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Satter om index till pid for att ha ett unikt index for varje observation\n",
    "pc1=pc1.reset_index().set_index('pid')\n",
    "# Tracknr raknar vilken trackning i ordningen en viss observation ar\n",
    "tracknr=pc1.groupby(['path','particle'])['frame'].rank()\n",
    "pc1['tracknr']=tracknr\n",
    "\n",
    "#Kontrollerar att de nya variablerna fungerar som de ska\n",
    "pc1.loc[pc1.nrtracks>5,['path','particle','frame','tracknr','nrtracks','cont_tot','displ_tot','dvz_tot']].set_index(['path','particle','frame']).sort_index().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving these readouts as pickle file: file name_xtratracking\n",
    "xtra_tracking=pc1.loc[:,['tracknr','nrtracks','cont_tot','displ_tot','dvz_tot']]\n",
    "xtra_tracking.to_pickle(base_name + '_xtratracking')\n",
    "print(len(xtra_tracking))\n",
    "xtra_tracking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
