{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the packages that are used. Also importing the actual data processing funcitons that have been defined in fl.py\n",
    "# For more info about how the data is being processed in this script, look in the fl.py document\n",
    "import fl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello This is how Pia would edit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast reload of external module\n",
    "import importlib\n",
    "importlib.reload(fl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pia: Set data path\n",
    "This is the path to where the data is being stored eg external drive. This path, including subfolders, will be searched for .nd2 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/jni/Dropbox/share-files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a dataframe called df_files that contains info about the data. Printing the start and end of the data frame showing \n",
    "# the info that it contains including the file name, pixel size, size of the images, number of channels, number of frames (timeponts)\n",
    "# Channels, frame rate, and position and size of the ROI\n",
    "df_files= fl.nd2_info_to_df(data_path)\n",
    "df_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identfying platelet objects in nd2-files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create config for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the settings for the object identification: It uses channel2 (X649) for object identifiction. \n",
    "#Settings for DoG and threshold\n",
    "conf = dict(\n",
    "            process_type = 'multi_process', # single_thread, multi_process, multi_thread\n",
    "            multi_workers = 7, # dont use too many\n",
    "            object_channel = 2,\n",
    "            intensity_channels = [0, 1],\n",
    "            dog_sigma1 = 1.7,\n",
    "            dog_sigma2 = 2.0,\n",
    "            threshold = 0.15,\n",
    "            peak_min_dist = 3,\n",
    "            z_dist = 2,\n",
    "            center_roi = True,\n",
    "            rotate = True,\n",
    "            rotate_angle = 45,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process loop \n",
    "Saves object dataframe and config file at location of the nd2-file. This is the most computationally heavy part of the analysis where objets are identified. For our standard tracking injuries it takes about 15 min per injury with the current settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pia: List the number of files list (range(XX)) in the data set that will be processed. If Whole data set use list(range(xx)) \n",
    "# If example injury use [X] (put hashtag on the one that you are not using).\n",
    "# Creating a new data frame for each injury called df_obj and these are saved as pickle files: df_filename\n",
    "\n",
    "fileIds_to_process = [0] \n",
    "#fileIds_to_process = list(range(66)) \n",
    "ivmObjects = fl.IvmObjects(conf)\n",
    "\n",
    "# loop for processing multiple nd2-files\n",
    "now_start = fl.get_datetime()\n",
    "time = Path(fl.get_datetime())\n",
    "time.mkdir(exist_ok=True)\n",
    "\n",
    "for fileId in fileIds_to_process:\n",
    "    # process file\n",
    "    file, frames = df_files.iloc[fileId][['file', 't']]\n",
    "    ivmObjects.add_nd2info(df_files.iloc[fileId]) #add nd2-file info to conf\n",
    "    \n",
    "    df_obj = ivmObjects.process_file(file, range(frames))#frames))\n",
    "    \n",
    "    #--------------------------------------------------------\n",
    "    #Niklas changed this section to change name of file and directory\n",
    "    file_path=Path(file)\n",
    "    now = fl.get_datetime()\n",
    "    df_filename = f'./{now_start}/{file_path.stem}.{now}.df.pkl'\n",
    "    conf_filename = f'./{now_start}/{file_path.stem}.{now}.conf.yml'\n",
    "    \n",
    "    #--------------------------------------------------------\n",
    "    \n",
    "    # save result\n",
    "    df_obj.to_pickle(df_filename)\n",
    "    fl.save_yaml(conf, conf_filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obj.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect image processing pipeline - here we can look at the outcome of the image processing for a selected injury"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create config for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = dict(\n",
    "            process_type = 'single_thread', # USE ONLY 'single_thread' for inspection\n",
    "            multi_workers = 7, # dont use too many\n",
    "            object_channel = 2,\n",
    "            intensity_channels = [0, 1],\n",
    "            dog_sigma1 = 1.7,\n",
    "            dog_sigma2 = 2.0,\n",
    "            threshold = 0.15,\n",
    "            peak_min_dist = 3,\n",
    "            z_dist = 2,\n",
    "            center_roi = True,\n",
    "            rotate = True,\n",
    "            rotate_angle = 45,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files= fl.nd2_info_to_df(data_path)\n",
    "df_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_files['file']=Path(df_files.file).stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process selected volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pia, select injury (file id) and time point (frame) that you want to visualise for effect of image processing\n",
    "fileId = 0\n",
    "frame = 70\n",
    "\n",
    "ivmObjects = fl.IvmObjects(conf)\n",
    "file, frames = df_files.iloc[fileId][['file', 't']]\n",
    "ivmObjects.add_nd2info(df_files.iloc[fileId]) #add nd2-file info to conf\n",
    "df_obj_insp = ivmObjects.process_file(file, [frame])\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obj_insp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect image processing steps - figure showing result of each image processing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list steps\n",
    "insp_steps = ivmObjects.inspect_steps\n",
    "step_names = [(stp, insp_steps[stp]['name']) for stp in insp_steps]\n",
    "print(step_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_levels = [0, 5, 10, 15, 20]\n",
    "figsize = (15,15)\n",
    "\n",
    "\n",
    "cols = len(insp_steps)\n",
    "rows = len(z_levels)\n",
    "\n",
    "fig, axs = plt.subplots(rows, cols, figsize=figsize, constrained_layout=True)\n",
    "for r, z in enumerate(z_levels):\n",
    "    for c, stp in enumerate(insp_steps):\n",
    "        axs[r, c].imshow(insp_steps[stp]['data'][...,z],\n",
    "                         vmin=insp_steps[stp]['data'].min(),\n",
    "                         vmax=insp_steps[stp]['data'].max(),\n",
    "                        cmap='nipy_spectral') \n",
    "        \n",
    "        axs[r, c].get_xaxis().set_ticks([])\n",
    "        axs[r, c].get_yaxis().set_ticks([])\n",
    "        \n",
    "        if r == 0:\n",
    "            axs[r, c].set_title(insp_steps[stp]['name'])\n",
    "        if c == 0:\n",
    "            axs[r, c].set_ylabel(z)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_level = 5\n",
    "fl.imshow((insp_steps[0]['data'][...,z_level])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect object positions - plot object positions at every 20th frame (approximately every min if frame rate 0.32). Chose which property to show in color (eg Calcium mean intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams['image.cmap'] = 'coolwarm'\n",
    "#plt.rcParams['image.cmap'] = 'jet_r'\n",
    "\n",
    "#Gor lista av dimensioner \n",
    "lims=['xs', 'ys', 'zs']\n",
    "limsv={}\n",
    "\n",
    "#Anger gransvarden for de olika dimensionerna genom att kolla minsta och storsta varde och plussa pa 40\n",
    "border=1.5\n",
    "for l in lims:\n",
    "    limsv[l]=df_obj[l].min()-20, df_obj[l].max()+20\n",
    "    \n",
    "col='path'\n",
    "row='c'\n",
    "hue='c'\n",
    "x='frame'\n",
    "y='z'\n",
    "unit='c'\n",
    "\n",
    "#Tar ut var 20:e frame fran frame 2 och framat\n",
    "frames=pd.unique(df_obj.frame)[::20]+1\n",
    "ncols=3\n",
    "nrows=len(frames)\n",
    "\n",
    "#Gor en lagom stor figur\n",
    "plt.figure(figsize=(ncols*4,nrows*3))\n",
    "\n",
    "#Valjer dimensioner att plotta \n",
    "cols=[('xs', 'ys'), ('xs', 'zs'), ('ys', 'zs')]\n",
    "\n",
    "### name väljer variabel att färgsätta plottarna med\n",
    "#name='cld'#name='stab'#name='c'#name='depth' #colorv=[1,2,4,8] #name='c2_max'\n",
    "name='int_mean'\n",
    "\n",
    "#vmin=0 #vmax=30#vmin=0\n",
    "#vmax=10 #vmax=400\n",
    "\n",
    "for r, f in enumerate(frames):\n",
    "    sel_f=df_obj[df_obj.frame==f]\n",
    "    \n",
    "    for c, xy in enumerate(cols):\n",
    "        ax=plt.subplot2grid((nrows, ncols), (r, c))\n",
    "        #plt.setp()\n",
    "        ax.scatter(sel_f[xy[0]], sel_f[xy[1]], alpha=0.5, c=sel_f[name], linewidth=0.1 )#, vmin=vmin, vmax=vmax,)\n",
    "        ax.set_title('Time (sec): '+ str(np.round(sel_f.time.mean())),fontsize=12)\n",
    "        ax.set_ylim(limsv[xy[1]])\n",
    "        ax.set_xlim(limsv[xy[0]])\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('')\n",
    "        ax.tick_params(labelsize=12)\n",
    "        #ax.ticklabel_format()\n",
    "        #ax.set_axis_bgcolor('black')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "#fname='e__' + name + '.png'\n",
    "\n",
    "#plt.savefig(fname, bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
